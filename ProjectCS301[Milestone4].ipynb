{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone-4"
      ],
      "metadata": {
        "id": "b1M64yRFfR3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up Environment "
      ],
      "metadata": {
        "id": "ECa_jliN4457"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify\n",
        "!pip install keras\n",
        "!pip install segmentation_models\n",
        "!pip install tensorflow==2.7.0\n",
        "!pip install nni\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from IPython.display import SVG\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os, re, sys, random, shutil, cv2\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify\n",
        "from PIL import Image\n",
        "import segmentation_models as sm\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "scaler = MinMaxScaler()\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras import applications, optimizers\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.utils import model_to_dot, plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, ZeroPadding2D, Dropout\n",
        "from nni.compression.tensorflow import Pruner"
      ],
      "metadata": {
        "id": "h90EbYfL5JlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "tf.random.set_seed(3)"
      ],
      "metadata": {
        "id": "q00q4Oy8fXBy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting the Google Drive"
      ],
      "metadata": {
        "id": "eqMhy4CC5NtK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xcbgDTBj5uzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6dae225-7618-4bc1-af83-56ba32742183"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob as gb\n",
        "from google.colab import drive\n",
        "# below storing the dataset that we had from our drive into root_directory \n",
        "root_directory = '/content/drive/MyDrive/Semantic segmentation dataset'\n",
        "patch_size = 256\n"
      ],
      "metadata": {
        "id": "mAxtqRRr55jw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Patchifying image\n",
        "\n",
        "image_dataset = []  \n",
        "for path, subdirs, files in os.walk(root_directory):\n",
        "    #print(path)  \n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    if dirname == 'images':   #Find all 'images' directories\n",
        "        images = os.listdir(path)  #List of all image names in this subdirectory\n",
        "        for i, image_name in enumerate(images):  \n",
        "            if image_name.endswith(\".jpg\"):   #Only read jpg images...\n",
        "               \n",
        "                image = cv2.imread(path+\"/\"+image_name, 1)  #Read each image as BGR\n",
        "                SIZE_X = (image.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                SIZE_Y = (image.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                image = Image.fromarray(image)\n",
        "                image = image.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n",
        "                #image = image.resize((SIZE_X, SIZE_Y))  #Try not to resize for semantic segmentation\n",
        "                image = np.array(image)             \n",
        "       \n",
        "                #Extract patches from each image\n",
        "                print(\"Now patchifying image:\", path+\"/\"+image_name)\n",
        "                patches_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)  #Step=256 for 256 patches means no overlap\n",
        "        \n",
        "                for i in range(patches_img.shape[0]):\n",
        "                    for j in range(patches_img.shape[1]):\n",
        "                        \n",
        "                        single_patch_img = patches_img[i,j,:,:]\n",
        "                        \n",
        "                        #Use minmaxscaler instead of just dividing by 255. \n",
        "                        single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)\n",
        "                        \n",
        "                        #single_patch_img = (single_patch_img.astype('float32')) / 255. \n",
        "                        single_patch_img = single_patch_img[0] #Drop the extra unecessary dimension that patchify adds.                               \n",
        "                        image_dataset.append(single_patch_img)"
      ],
      "metadata": {
        "id": "0IXZp5cb6Jkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#patchifying masks\n",
        "mask_dataset = []  \n",
        "for path, subdirs, files in os.walk(root_directory):\n",
        "    #print(path)  \n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    if dirname == 'masks':   #Find all 'images' directories\n",
        "        masks = os.listdir(path)  #List of all image names in this subdirectory\n",
        "        for i, mask_name in enumerate(masks):  \n",
        "            if mask_name.endswith(\".png\"):   #Only read png images... (masks in this dataset)\n",
        "               \n",
        "                mask = cv2.imread(path+\"/\"+mask_name, 1)  #Read each image as Grey (or color but remember to map each color to an integer)\n",
        "                mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\n",
        "                SIZE_X = (mask.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                SIZE_Y = (mask.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                mask = Image.fromarray(mask)\n",
        "                mask = mask.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n",
        "                #mask = mask.resize((SIZE_X, SIZE_Y))  #Try not to resize for semantic segmentation\n",
        "                mask = np.array(mask)             \n",
        "       \n",
        "                #Extract patches from each image\n",
        "                print(\"Now patchifying mask:\", path+\"/\"+mask_name)\n",
        "                patches_mask = patchify(mask, (patch_size, patch_size, 3), step=patch_size)  #Step=256 for 256 patches means no overlap\n",
        "        \n",
        "                for i in range(patches_mask.shape[0]):\n",
        "                    for j in range(patches_mask.shape[1]):\n",
        "                        \n",
        "                        single_patch_mask = patches_mask[i,j,:,:]\n",
        "                        #single_patch_img = (single_patch_img.astype('float32')) / 255. #No need to scale masks, but you can do it if you want\n",
        "                        single_patch_mask = single_patch_mask[0] #Drop the extra unecessary dimension that patchify adds.                               \n",
        "                        mask_dataset.append(single_patch_mask) \n",
        " \n",
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset =  np.array(mask_dataset)"
      ],
      "metadata": {
        "id": "BL-K2SEK6Yec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###########################################################################\n",
        "\"\"\"\n",
        "RGB to HEX: (Hexadecimel --> base 16)\n",
        "This number divided by sixteen (integer division; ignoring any remainder) gives \n",
        "the first hexadecimal digit (between 0 and F, where the letters A to F represent \n",
        "the numbers 10 to 15). The remainder gives the second hexadecimal digit. \n",
        "0-9 --> 0-9\n",
        "10-15 --> A-F\n",
        "Example: RGB --> R=201, G=, B=\n",
        "R = 201/16 = 12 with remainder of 9. So hex code for R is C9 (remember C=12)\n",
        "Calculating RGB from HEX: #3C1098\n",
        "3C = 3*16 + 12 = 60\n",
        "10 = 1*16 + 0 = 16\n",
        "98 = 9*16 + 8 = 152\n",
        "\"\"\"\n",
        "#Convert HEX to RGB array\n",
        "# Try the following to understand how python handles hex values...\n",
        "a=int('3C', 16)  #3C with base 16. Should return 60. \n",
        "print(a)\n",
        "#Do the same for all RGB channels in each hex code to convert to RGB\n",
        "Building = '#3C1098'.lstrip('#')\n",
        "Building = np.array(tuple(int(Building[i:i+2], 16) for i in (0, 2, 4))) # 60, 16, 152\n",
        "\n",
        "Land = '#8429F6'.lstrip('#')\n",
        "Land = np.array(tuple(int(Land[i:i+2], 16) for i in (0, 2, 4))) #132, 41, 246\n",
        "\n",
        "Road = '#6EC1E4'.lstrip('#') \n",
        "Road = np.array(tuple(int(Road[i:i+2], 16) for i in (0, 2, 4))) #110, 193, 228\n",
        "\n",
        "Vegetation =  'FEDD3A'.lstrip('#') \n",
        "Vegetation = np.array(tuple(int(Vegetation[i:i+2], 16) for i in (0, 2, 4))) #254, 221, 58\n",
        "\n",
        "Water = 'E2A929'.lstrip('#') \n",
        "Water = np.array(tuple(int(Water[i:i+2], 16) for i in (0, 2, 4))) #226, 169, 41\n",
        "\n",
        "Unlabeled = '#9B9B9B'.lstrip('#') \n",
        "Unlabeled = np.array(tuple(int(Unlabeled[i:i+2], 16) for i in (0, 2, 4))) #155, 155, 155\n",
        "\n",
        "label = single_patch_mask\n",
        "\n",
        "# Now replace RGB to integer values to be used as labels.\n",
        "#Find pixels with combination of RGB for the above defined arrays...\n",
        "#if matches then replace all values in that pixel with a specific integer\n",
        "def rgb_to_2D_label(label):\n",
        "    \"\"\"\n",
        "    Suply our labale masks as input in RGB format. \n",
        "    Replace pixels with specific RGB values ...\n",
        "    \"\"\"\n",
        "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
        "    label_seg [np.all(label == Building,axis=-1)] = 0\n",
        "    label_seg [np.all(label==Land,axis=-1)] = 1\n",
        "    label_seg [np.all(label==Road,axis=-1)] = 2\n",
        "    label_seg [np.all(label==Vegetation,axis=-1)] = 3\n",
        "    label_seg [np.all(label==Water,axis=-1)] = 4\n",
        "    label_seg [np.all(label==Unlabeled,axis=-1)] = 5\n",
        "    \n",
        "    label_seg = label_seg[:,:,0]  #Just take the first channel, no need for all 3 channels\n",
        "    \n",
        "    return label_seg\n",
        "\n",
        "labels = []\n",
        "for i in range(mask_dataset.shape[0]):\n",
        "    label = rgb_to_2D_label(mask_dataset[i])\n",
        "    labels.append(label)    \n",
        "\n",
        "labels = np.array(labels)   \n",
        "labels = np.expand_dims(labels, axis=3)\n",
        " \n",
        "\n",
        "print(\"Unique labels in label dataset are: \", np.unique(labels))"
      ],
      "metadata": {
        "id": "eOt8D71f8WBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = len(np.unique(labels))\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "labels_cat = to_categorical(labels, num_classes=n_classes)"
      ],
      "metadata": {
        "id": "Jr-1KitN8cfH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "            )\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "72QeQxBVffTg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "\n",
        "\n",
        "################################################################\n",
        "def multi_unet_model(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
        "#Build the model\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
        "    s = inputs\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.2)(c1)  # Original 0.1\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    \n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.2)(c2)  # Original 0.1\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "     \n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "     \n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "     \n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    #Expansive path \n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "     \n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "     \n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.2)(c8)  # Original 0.1\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "     \n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.2)(c9)  # Original 0.1\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "    layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10),\n",
        "\n",
        "    keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
        "    layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "    layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10),\n",
        "\n",
        "    keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
        "    layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "    layers.LeakyReLU(alpha=0.2),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "    layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10),\n",
        "\n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9) \n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
        "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    #model.summary()\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "keV87-81f6Ra"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Model \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_dataset, labels_cat, test_size = 0.20, random_state = 42)"
      ],
      "metadata": {
        "id": "E9ol43QYf9lJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = X_train.shape[1]\n",
        "IMG_WIDTH  = X_train.shape[2]\n",
        "IMG_CHANNELS = X_train.shape[3]"
      ],
      "metadata": {
        "id": "7zMKj4TLghEs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the teacher\n",
        "teacher = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
        "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10),\n",
        "    ],\n",
        "    name=\"teacher\",\n",
        ")\n",
        "\n",
        "# Create the student\n",
        "student = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
        "        layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10),\n",
        "    ],\n",
        "    name=\"student\",\n",
        ")\n",
        "\n",
        "student_scratch = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
        "        layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10),\n",
        "    ],\n",
        "    name=\"student_scratch\",\n",
        ")\n",
        "\n",
        "# Clone student for later comparison\n",
        "#student_scratch = keras.models.clone_model(student)"
      ],
      "metadata": {
        "id": "CWu8qbzaffw2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.summary()"
      ],
      "metadata": {
        "id": "KanNSngmhDWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student.summary()"
      ],
      "metadata": {
        "id": "QwPpejamhEXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = [0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666]\n",
        "dice_loss = sm.losses.DiceLoss(class_weights=weights) \n",
        "focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)"
      ],
      "metadata": {
        "id": "nQ2oWfXm8gqR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS"
      ],
      "metadata": {
        "id": "38ZwVgYe8jXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "wnQOEdUE9J8G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)"
      ],
      "metadata": {
        "id": "uHketH618k2a"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics=['accuracy', jacard_coef]"
      ],
      "metadata": {
        "id": "3btGJ1I_8rNE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
        "    \n",
        "teacher1 = get_model()\n",
        "student1 = get_model()"
      ],
      "metadata": {
        "id": "izDIwJs38weP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train teacher as usual\n",
        "teacher1.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=total_loss,\n",
        "    metrics=metrics,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "1B6qcFhmhgD0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "techer_Val = teacher1.fit(X_train, y_train, \n",
        "                    batch_size = 16, \n",
        "                    verbose=1, \n",
        "                    epochs=50, \n",
        "                    validation_data=(X_test, y_test), \n",
        "                    shuffle=False)"
      ],
      "metadata": {
        "id": "SZQ_8fX_ACur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher1.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "0qX1Apytm_iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and compile distiller\n",
        "distiller = Distiller(student=student1, teacher=teacher1)\n",
        "distiller.compile(optimizer=keras.optimizers.Adam(),metrics=metrics,student_loss_fn=total_loss,distillation_loss_fn=keras.losses.KLDivergence(),alpha=0.1,temperature=10)"
      ],
      "metadata": {
        "id": "o7E9xJZQnA2x"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_Val = distiller.fit(X_train, y_train, \n",
        "                    batch_size = 16, \n",
        "                    verbose=1, \n",
        "                    epochs=50, \n",
        "                    validation_data=(X_test, y_test), \n",
        "                    shuffle=False)"
      ],
      "metadata": {
        "id": "y36iP6_go9gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distiller.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "MVP4KJxix3j6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the training and validation accuracy and loss at each epoch\n",
        "history = student_Val\n",
        "loss = history.history['student_loss']\n",
        "val_loss = history.history['val_student_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tr-tCu0CHAyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['jacard_coef']\n",
        "val_acc = history.history['val_jacard_coef']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training IoU')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation IoU')\n",
        "plt.title('Training and validation IoU')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9qAg32XvHCcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=student1.predict(X_test)\n",
        "y_pred_argmax=np.argmax(y_pred, axis=3)\n",
        "y_test_argmax=np.argmax(y_test, axis=3)\n"
      ],
      "metadata": {
        "id": "7DmCkN7EHGPA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import MeanIoU\n",
        "n_classes = 6\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(y_test_argmax, y_pred_argmax)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ],
      "metadata": {
        "id": "kh3E6vEZHLF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (10):\n",
        "  test_img_number = random.randint(0, len(X_test))\n",
        "  test_img = X_test[test_img_number]\n",
        "  ground_truth=y_test_argmax[test_img_number]\n",
        "\n",
        "  test_img_input=np.expand_dims(test_img, 0)\n",
        "  prediction = (student1.predict(test_img_input))\n",
        "  predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.subplot(231)\n",
        "  plt.title('Testing Image')\n",
        "  plt.imshow(test_img)\n",
        "  plt.subplot(232)\n",
        "  plt.title('Testing Label')\n",
        "  plt.imshow(ground_truth)\n",
        "  plt.subplot(233)\n",
        "  plt.title('Prediction image')\n",
        "  plt.imshow(predicted_img)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "-ms5GnN0HOQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "predictionVal = np.array(y_pred_argmax)\n",
        "predictionVal = np.stack(predictionVal, axis=1).flatten()\n",
        "trueVal = np.array(y_test_argmax)\n",
        "trueVal = np.stack(trueVal, axis=1).flatten()\n",
        "yTest = predictionVal.tolist()\n",
        "xTest = trueVal.tolist()\n",
        "labelVal = np.unique(labels).tolist()\n",
        "cmVal = confusion_matrix(xTest, yTest, labels=labelVal)\n",
        "precisionVal = precision_score(xTest, yTest, average='micro')\n",
        "recallVal = recall_score(xTest, yTest, average='micro')\n",
        "print(\"This is the calculated Precision Value\", precisionVal , \"and this is the calculated Recall Value\", recallVal)\n",
        "\n",
        "precisionVal, recallVal, thresholds = precision_recall_curve(xTest, yTest, pos_label=1)\n",
        "plt.plot(precisionVal, recallVal)\n",
        "plt.xlabel('Precision')\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.title(\"precision_recall_curve\")\n",
        "plt.plot()\n"
      ],
      "metadata": {
        "id": "DG5jnmlyytcH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}